# Week-5-Lecture
Week-5-Lecture

### 로봇도 다른 로봇의 시선에서 세상을 볼 수 있을까?


* 이 논문은 로봇이 눈으로만 보고 다른 로봇의 행동을 예측할 수 있는가를 실험한 연구이다. 언어나 명령 없이 오직 카메라 영상만으로 상대의 행동을 이해하려 했다.

* 연구팀은 행동자 로봇과 관찰자 AI를 만들고, 행동자가 네 가지 방식(직선, 팔꿈치형, 지그재그, 장애물 회피)으로 움직이게 했다. 관찰자는 위에서 이를 보고 다음 행동을 영상으로 예측했다.

* 관찰자 AI는 98.5%의 정확도로 행동자의 움직임과 결과를 맞혔다. 즉, 로봇이 상징이나 언어 없이 순수한 시각 정보만으로 미래 행동을 상상할 수 있다는 뜻이다.

* ‘잘못된 믿음 실험(False-Belief Test)’도 진행했는데, 이는 관찰자가 행동자의 시야와 자신의 시야를 구분할 수 있는지 보는 시험이다. 학습 후에는 관찰자가 행동자의 입장 차이를 인식할 수 있었다.

* 결론적으로 이 연구는 로봇이 시각적 사고만으로도 타인의 의도나 행동을 추론할 수 있음을 보여준다. 이는 인간의 ‘마음이론(Theory of Mind)’의 초기 형태를 기계가 모방할 수 있음을 시사한다

### 마음이론(Theory of Mind)
* 마음이론(Theory of Mind)은 다른 사람의 생각, 감정, 의도, 믿음이 나와 다를 수 있음을 이해하는 능력이다.
* 예를 들어, 친구가 사탕이 있는 상자를 비었다고 착각한다면, 우리는 그가 ‘틀린 믿음’을 가지고 있음을 알 수 있다. 이러한 사고는 단순한 관찰이 아니라 타인의 마음 상태를 추론하는 인지적 능력이다.
* 인간은 보통 3~4세 무렵부터 이 능력이 발달하며, 사회적 소통, 협력, 공감, 속임수 같은 복잡한 행동의 기초가 된다. 인공지능 연구에서는 이를 로봇이 타인의 행동을 예측하거나 의도를 이해하도록 하는 핵심 모델로 응용한다.


### 참고 파일

<b>[(3Blue1Browm 바로가기)](https://www.youtube.com/watch?v=wjZofJX0v4M&t=38s)</b> 
<b>[(3Blue1Browm 한국어 바로가기)](https://www.youtube.com/@3Blue1BrownKR)</b> 


* 감성컴퓨팅의 최근동향 논문:A Systematic Review on Affective Computing
* 감성컴퓨팅 최근동향 강의 자료
* 3Blue1Brown 설명자료
* 나동빈 깃허브 설명

